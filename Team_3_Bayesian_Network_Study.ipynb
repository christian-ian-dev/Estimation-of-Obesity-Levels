{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christian-ian-dev/Estimation-of-Obesity-Levels/blob/Bayesian-Model/Team_3_Bayesian_Network_Study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the official UCI Machine Learning Repository library and pgmpy\n",
        "!pip install ucimlrepo pgmpy"
      ],
      "metadata": {
        "id": "px86OlQkDdwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Obesity Levels Study — Bayesian Networks (BN)\n",
        "# =============================================================================\n",
        "# 1) Starts with requested pgmpy imports\n",
        "# 2) Starts with requested PyMC imports\n",
        "# 3) Creates bins for numeric features using pd.cut\n",
        "# 4) Provides TWO BN approaches: pgmpy + PyMC\n",
        "#\n",
        "# Outputs:\n",
        "#   outputs_bn/\n",
        "#     cleaned_dataset_bn.csv\n",
        "#     pgmpy/bn_structure_edges.csv\n",
        "#     pymc/pymc_cpt_posterior_summary.csv\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy import stats\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# =============================================================================\n",
        "# Config + mappings\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class Config:\n",
        "    uci_id: int = 544\n",
        "    output_dir: str = \"outputs_bn\"\n",
        "    exclude_insufficient_weight: bool = True\n",
        "    random_state: int = 42\n",
        "\n",
        "    # PyMC can get slow with many nodes; default to a subset.\n",
        "    pymc_nodes: Tuple[str, ...] = (\n",
        "        \"family_history_overweight\",\n",
        "        \"high_calorie_food_freq\",\n",
        "        \"vegetable_intake_bin\",\n",
        "        \"physical_activity_bin\",\n",
        "        \"technology_use_bin\",\n",
        "        \"obesity_level_3cat\",\n",
        "    )\n",
        "\n",
        "    draws: int = 1200\n",
        "    tune: int = 800\n",
        "    chains: int = 2\n",
        "    target_accept: float = 0.9\n",
        "\n",
        "\n",
        "RENAME_MAP: Dict[str, str] = {\n",
        "    \"Gender\": \"gender\",\n",
        "    \"Age\": \"age\",\n",
        "    \"Height\": \"height_m\",\n",
        "    \"Weight\": \"weight_kg\",\n",
        "    \"family_history_with_overweight\": \"family_history_overweight\",\n",
        "    \"FAVC\": \"high_calorie_food_freq\",\n",
        "    \"FCVC\": \"vegetable_intake_freq\",\n",
        "    \"NCP\": \"num_main_meals\",\n",
        "    \"CAEC\": \"snacking_between_meals\",\n",
        "    \"SMOKE\": \"smoker\",\n",
        "    \"CH2O\": \"water_intake_freq\",\n",
        "    \"SCC\": \"calorie_monitoring\",\n",
        "    \"FAF\": \"physical_activity_freq\",\n",
        "    \"TUE\": \"technology_use_time\",\n",
        "    \"CALC\": \"alcohol_intake_freq\",\n",
        "    \"MTRANS\": \"transportation_mode\",\n",
        "    \"NObeyesdad\": \"obesity_level_raw\",\n",
        "}\n",
        "\n",
        "OBESITY_3LVL_MAP: Dict[str, str] = {\n",
        "    \"Insufficient_Weight\": \"Insufficient\",\n",
        "    \"Normal_Weight\": \"Normal\",\n",
        "    \"Overweight_Level_I\": \"Overweight\",\n",
        "    \"Overweight_Level_II\": \"Overweight\",\n",
        "    \"Obesity_Type_I\": \"Obese\",\n",
        "    \"Obesity_Type_II\": \"Obese\",\n",
        "    \"Obesity_Type_III\": \"Obese\",\n",
        "}\n",
        "\n",
        "OBESITY_ORDER = [\"Normal\", \"Overweight\", \"Obese\"]\n",
        "\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Load data (UCI)\n",
        "# =============================================================================\n",
        "def load_uci_df(cfg: Config) -> pd.DataFrame:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "    obesity = fetch_ucirepo(id=cfg.uci_id)\n",
        "    X = obesity.data.features\n",
        "    y = obesity.data.targets\n",
        "    return pd.concat([X, y], axis=1)\n",
        "\n",
        "\n",
        "def rename_and_recode(df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
        "    df = df.copy().rename(columns=RENAME_MAP)\n",
        "    df[\"obesity_level_3cat\"] = df[\"obesity_level_raw\"].map(OBESITY_3LVL_MAP)\n",
        "\n",
        "    if cfg.exclude_insufficient_weight:\n",
        "        df = df[df[\"obesity_level_3cat\"].ne(\"Insufficient\")].copy()\n",
        "\n",
        "    df[\"obesity_level_3cat\"] = pd.Categorical(df[\"obesity_level_3cat\"], categories=OBESITY_ORDER, ordered=True)\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3) Manual bins for numeric features (pd.cut style)\n",
        "# =============================================================================\n",
        "def add_manual_bins(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create binned versions of numeric/ordinal-numeric features using pd.cut.\"\"\"\n",
        "    df_lab = df.copy()\n",
        "\n",
        "    # Example provided:\n",
        "    df_lab[\"age_bin\"] = pd.cut(\n",
        "        df_lab[\"age\"].astype(float),\n",
        "        bins=[0, 30, 45, 60, 100],\n",
        "        labels=[\"Young\", \"Mid\", \"Senior\", \"Elder\"],\n",
        "        include_lowest=True,\n",
        "    ).astype(str)\n",
        "\n",
        "    # Height bins (meters)\n",
        "    df_lab[\"height_bin\"] = pd.cut(\n",
        "        df_lab[\"height_m\"].astype(float),\n",
        "        bins=[1.0, 1.5, 1.65, 1.8, 2.2],\n",
        "        labels=[\"Short\", \"Average\", \"Tall\", \"VeryTall\"],\n",
        "        include_lowest=True,\n",
        "    ).astype(str)\n",
        "\n",
        "    # Weight bins (kg)\n",
        "    df_lab[\"weight_bin\"] = pd.cut(\n",
        "        df_lab[\"weight_kg\"].astype(float),\n",
        "        bins=[0, 60, 80, 100, 140, 250],\n",
        "        labels=[\"Light\", \"Mid\", \"Heavy\", \"VeryHeavy\", \"Extreme\"],\n",
        "        include_lowest=True,\n",
        "    ).astype(str)\n",
        "\n",
        "    # Ordinal frequency-type numeric variables → Low/Medium/High bins\n",
        "    def low_med_high(x: pd.Series, cuts: List[float], labels: List[str], outcol: str) -> None:\n",
        "        df_lab[outcol] = pd.cut(x.astype(float), bins=cuts, labels=labels, include_lowest=True).astype(str)\n",
        "\n",
        "    low_med_high(df_lab[\"vegetable_intake_freq\"], [0, 1.5, 2.5, 10], [\"Low\", \"Medium\", \"High\"], \"vegetable_intake_bin\")\n",
        "    low_med_high(df_lab[\"num_main_meals\"], [0, 2.5, 3.5, 10], [\"Low\", \"Medium\", \"High\"], \"num_main_meals_bin\")\n",
        "    low_med_high(df_lab[\"water_intake_freq\"], [0, 1.5, 2.5, 10], [\"Low\", \"Medium\", \"High\"], \"water_intake_bin\")\n",
        "    low_med_high(df_lab[\"physical_activity_freq\"], [-0.1, 0.5, 2.0, 10], [\"Low\", \"Medium\", \"High\"], \"physical_activity_bin\")\n",
        "    low_med_high(df_lab[\"technology_use_time\"], [-0.1, 0.5, 1.5, 10], [\"Low\", \"Medium\", \"High\"], \"technology_use_bin\")\n",
        "\n",
        "    return df_lab\n",
        "\n",
        "\n",
        "def build_bn_dataset(df_binned: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Select BN-friendly columns and cast everything to string categories.\"\"\"\n",
        "    keep_cols = [\n",
        "        \"gender\",\n",
        "        \"family_history_overweight\",\n",
        "        \"high_calorie_food_freq\",\n",
        "        \"snacking_between_meals\",\n",
        "        \"smoker\",\n",
        "        \"calorie_monitoring\",\n",
        "        \"alcohol_intake_freq\",\n",
        "        \"transportation_mode\",\n",
        "        \"age_bin\",\n",
        "        \"height_bin\",\n",
        "        \"weight_bin\",\n",
        "        \"vegetable_intake_bin\",\n",
        "        \"num_main_meals_bin\",\n",
        "        \"water_intake_bin\",\n",
        "        \"physical_activity_bin\",\n",
        "        \"technology_use_bin\",\n",
        "        \"obesity_level_3cat\",\n",
        "    ]\n",
        "    cols = [c for c in keep_cols if c in df_binned.columns]\n",
        "    df_bn = df_binned[cols].copy()\n",
        "    for c in df_bn.columns:\n",
        "        df_bn[c] = df_bn[c].astype(str)\n",
        "    return df_bn"
      ],
      "metadata": {
        "id": "x1ne0XU4I0sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------\n",
        "# 4A) pgmpy imports\n",
        "# ------------------------------------------------------------------\n",
        "from pgmpy.estimators import HillClimbSearch, BIC, ExpertKnowledge, BayesianEstimator, PC\n",
        "from pgmpy.models import DiscreteBayesianNetwork\n",
        "from pgmpy.inference import VariableElimination\n",
        "import pandas as pd\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =============================================================================\n",
        "# pgmpy: structure learning + parameter learning + inference\n",
        "# =============================================================================\n",
        "\n",
        "def fit_pgmpy_bn(df_bn: pd.DataFrame, outdir: str):\n",
        "    # Define expert knowledge\n",
        "    expert = ExpertKnowledge(forbidden_edges=[], required_edges=[])\n",
        "\n",
        "    # 1) Score-based: Hill Climb + BIC, Structure Learning\n",
        "    hc = HillClimbSearch(df_bn)\n",
        "    best_model = hc.estimate(scoring_method=BIC(df_bn), expert_knowledge=expert, max_indegree=5)\n",
        "\n",
        "    # Initialize the BN and ensure all nodes are present\n",
        "    model_hc = DiscreteBayesianNetwork(best_model.edges())\n",
        "    model_hc.add_nodes_from(df_bn.columns)\n",
        "\n",
        "    # 2) Parameter Learning (Fit CPDs)\n",
        "    model_hc.fit(df_bn, estimator=BayesianEstimator, prior_type='BDeu')\n",
        "\n",
        "    # Save structure\n",
        "    edges = list(model_hc.edges())\n",
        "    pd.DataFrame(edges, columns=[\"from\", \"to\"]).to_csv(os.path.join(outdir, \"bn_structure_edges.csv\"), index=False)\n",
        "\n",
        "    # 3) Inference\n",
        "    infer = VariableElimination(model_hc)\n",
        "    q0 = infer.query(variables=[\"obesity_level_3cat\"])\n",
        "\n",
        "    with open(os.path.join(outdir, \"example_queries.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"Baseline P(obesity_level_3cat):\\n\")\n",
        "        f.write(str(q0))\n",
        "        f.write(\"\\n\\nTip: evidence must match the string labels in cleaned_dataset_bn.csv\\n\")\n",
        "\n",
        "    # 4) Constraint-based: PC algorithm for comparison\n",
        "    pc_est = PC(df_bn)\n",
        "    best_pc = pc_est.estimate(expert_knowledge=expert)\n",
        "    model_pc = DiscreteBayesianNetwork()\n",
        "    model_pc.add_nodes_from(df_bn.columns)\n",
        "    for u, v in best_pc.edges():\n",
        "        try:\n",
        "            model_pc.add_edge(u, v)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    return edges\n",
        "\n",
        "def plot_bn(model, title):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.circular_layout(model)\n",
        "    nx.draw(model, pos, with_labels=True, node_color='lightblue',\n",
        "            node_size=3000, font_size=10, arrowsize=20, edge_color='gray')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d5jE8W9_Mrqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------\n",
        "# 4B) PyMC imports\n",
        "# ------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import get_ipython\n",
        "ip = get_ipython()\n",
        "\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# =============================================================================\n",
        "# PyMC BN: CPT-based posterior for a subset of nodes\n",
        "# =============================================================================\n",
        "def build_parent_map(edges: List[Tuple[str, str]], nodes: List[str]) -> Dict[str, List[str]]:\n",
        "    parents = {n: [] for n in nodes}\n",
        "    for u, v in edges:\n",
        "        if u in parents and v in parents:\n",
        "            parents[v].append(u)\n",
        "    return parents\n",
        "\n",
        "\n",
        "def encode_categories(df_bn: pd.DataFrame, nodes: List[str]) -> Tuple[pd.DataFrame, Dict[str, List[str]]]:\n",
        "    df_enc = pd.DataFrame(index=df_bn.index)\n",
        "    categories: Dict[str, List[str]] = {}\n",
        "    for n in nodes:\n",
        "        cats = pd.Index(sorted(df_bn[n].astype(str).unique()))\n",
        "        categories[n] = cats.tolist()\n",
        "        df_enc[n] = pd.Categorical(df_bn[n].astype(str), categories=cats).codes\n",
        "    return df_enc, categories\n",
        "\n",
        "\n",
        "def parent_state_index(row: np.ndarray, parent_cols: List[int], parent_card: List[int]) -> int:\n",
        "    idx = 0\n",
        "    mult = 1\n",
        "    for col, card in zip(reversed(parent_cols), reversed(parent_card)):\n",
        "        idx += int(row[col]) * mult\n",
        "        mult *= card\n",
        "    return idx\n",
        "\n",
        "\n",
        "def fit_pymc_bn(df_bn: pd.DataFrame, edges: List[Tuple[str, str]], cfg: Config, outdir: str) -> None:\n",
        "    nodes = list(cfg.pymc_nodes)\n",
        "    edges_sub = [(u, v) for (u, v) in edges if u in nodes and v in nodes]\n",
        "    parents = build_parent_map(edges_sub, nodes)\n",
        "\n",
        "    df_enc, categories = encode_categories(df_bn, nodes)\n",
        "    card = {n: len(categories[n]) for n in nodes}\n",
        "\n",
        "    node_index = {n: i for i, n in enumerate(nodes)}\n",
        "    data_matrix = df_enc[nodes].values\n",
        "\n",
        "    parent_cfg_idx = {}\n",
        "    parent_cfg_size = {}\n",
        "\n",
        "    for n in nodes:\n",
        "        ps = parents[n]\n",
        "        if not ps:\n",
        "            parent_cfg_size[n] = 1\n",
        "            parent_cfg_idx[n] = np.zeros(len(df_enc), dtype=int)\n",
        "        else:\n",
        "            cols = [node_index[p] for p in ps]\n",
        "            cards = [card[p] for p in ps]\n",
        "            parent_cfg_size[n] = int(np.prod(cards))\n",
        "            idxs = np.zeros(len(df_enc), dtype=int)\n",
        "            for i in range(len(df_enc)):\n",
        "                idxs[i] = parent_state_index(data_matrix[i], cols, cards)\n",
        "            parent_cfg_idx[n] = idxs\n",
        "\n",
        "    with pm.Model() as model:\n",
        "        cpt = {}\n",
        "        for n in nodes:\n",
        "            k = card[n]\n",
        "            m = parent_cfg_size[n]\n",
        "            alpha = np.ones((m, k), dtype=float)\n",
        "            cpt[n] = pm.Dirichlet(f\"cpt_{n}\", a=alpha, shape=(m, k))\n",
        "\n",
        "        for n in nodes:\n",
        "            obs = df_enc[n].values\n",
        "            idx = parent_cfg_idx[n]\n",
        "            p = cpt[n][idx]\n",
        "            pm.Categorical(f\"obs_{n}\", p=p, observed=obs)\n",
        "\n",
        "        idata = pm.sample(\n",
        "            draws=cfg.draws,\n",
        "            tune=cfg.tune,\n",
        "            chains=cfg.chains,\n",
        "            target_accept=cfg.target_accept,\n",
        "            random_seed=cfg.random_state,\n",
        "            progressbar=True,\n",
        "        )\n",
        "\n",
        "    rows = []\n",
        "    for n in nodes:\n",
        "        arr = idata.posterior[f\"cpt_{n}\"].mean(dim=(\"chain\", \"draw\")).values\n",
        "        for m in range(arr.shape[0]):\n",
        "            for k in range(arr.shape[1]):\n",
        "                rows.append({\n",
        "                    \"node\": n,\n",
        "                    \"parent_cfg_index\": m,\n",
        "                    \"state_label\": categories[n][k],\n",
        "                    \"posterior_mean_prob\": float(arr[m, k]),\n",
        "                })\n",
        "    pd.DataFrame(rows).to_csv(os.path.join(outdir, \"pymc_cpt_posterior_summary.csv\"), index=False)\n",
        "\n",
        "    meta = {\n",
        "        \"nodes\": nodes,\n",
        "        \"edges\": edges_sub,\n",
        "        \"categories\": categories,\n",
        "        \"parents\": parents,\n",
        "        \"cardinalities\": card,\n",
        "        \"parent_cfg_size\": parent_cfg_size,\n",
        "        \"note\": \"parent_cfg_index uses mixed-radix ordering over parents in parents[node] order.\",\n",
        "    }\n",
        "    with open(os.path.join(outdir, \"pymc_metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    cfg = Config()\n",
        "\n",
        "    ensure_dir(cfg.output_dir)\n",
        "    ensure_dir(os.path.join(cfg.output_dir, \"pgmpy\"))\n",
        "    ensure_dir(os.path.join(cfg.output_dir, \"pymc\"))\n",
        "\n",
        "    raw = load_uci_df(cfg)\n",
        "    df = rename_and_recode(raw, cfg)\n",
        "\n",
        "    df_binned = add_manual_bins(df)\n",
        "    df_bn = build_bn_dataset(df_binned)\n",
        "\n",
        "    df_bn.to_csv(os.path.join(cfg.output_dir, \"cleaned_dataset_bn.csv\"), index=False)\n",
        "\n",
        "    edges = fit_pgmpy_bn(df_bn, outdir=os.path.join(cfg.output_dir, \"pgmpy\"))\n",
        "    fit_pymc_bn(df_bn, edges=edges, cfg=cfg, outdir=os.path.join(cfg.output_dir, \"pymc\"))\n",
        "\n",
        "    print(\"Done. Outputs written to:\", cfg.output_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Wow59qoTMsvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}